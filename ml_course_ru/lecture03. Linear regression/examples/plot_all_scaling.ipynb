{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Сравните эффекты различных масштабных преобразователей на данных с выбросами\n",
    "\n",
    "Признак 0 (средний доход в блоке) и признак 5 (количество проживающих семей) в  \n",
    "`California housing dataset\n",
    "<http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html>` имеют совершенно\n",
    "разные масштабы и содержат очень большие выбросы. Две эти характеристики приводят\n",
    "к сложностям в визуализации данных и, что более важно, они могут понизить \n",
    "производительность прогнозирования многих алгоритмов машинного обучения. \n",
    "Немаштабированные данные могут также замедлить или предотвратить сходимость\n",
    "многих оценщиков, основанных на градиенте. \n",
    "\n",
    "Однако многие оценщики разработаны с допущением, что каждый признак принимает \n",
    "значения близкие к нулю или, что более важно, что все признаки варьируются на \n",
    "сопоставимых масштабах. В конкретном, метричном и градиентном оценщике обычно \n",
    "подразумевается приблизительные стандартизированные данные (центрированные признаки \n",
    "с единичными отклонениями). Важным мсключением являются оценщики на основе дерева \n",
    "решений, устойчивые к произвольному масштабированию данных. \n",
    "\n",
    "\n",
    "\n",
    "Данный пример использует различные преобразователи, преобразователи масштаба и \n",
    "нормализаторы, чтобы выдать данные в заранее заданном диапазоне.\n",
    "\n",
    "\n",
    "Преобразователи масштаба - это линейные (точнее, аффинные) преобразователи, \n",
    "отличающиеся друг от друга путем оценки параметров, используемых для сдвига\n",
    "и масштабирования каждого признака.\n",
    "\n",
    "``QuantileTransformer`` предоставляет нелинейное преобразование, в котором расстояния между предельными\n",
    "выбросами и не-выбросами сокращены.\n",
    " \n",
    " \n",
    "В отличие от предыдущих преобразований, нормализация относится к каждому \n",
    "образцу преобразования, вместо преобразования на признак.\n",
    "\n",
    "\n",
    "Следующий код довольно подробный, не стесняйтес перепрыгнуть прямиком к анализу результатов_.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author:  Raghav RV <rvraghav93@gmail.com>\n",
    "#          Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
    "#          Thomas Unterthiner\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "dataset = fetch_california_housing()\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "\n",
    "# Take only 2 features to make visualization easier\n",
    "# Feature of 0 has a long tail distribution.\n",
    "# Feature 5 has a few but very large outliers.\n",
    "\n",
    "X = X_full[:, [0, 5]]\n",
    "\n",
    "distributions = [\n",
    "    ('Unscaled data', X),\n",
    "    ('Data after standard scaling',\n",
    "        StandardScaler().fit_transform(X)),\n",
    "    ('Data after min-max scaling',\n",
    "        MinMaxScaler().fit_transform(X)),\n",
    "    ('Data after max-abs scaling',\n",
    "        MaxAbsScaler().fit_transform(X)),\n",
    "    ('Data after robust scaling',\n",
    "        RobustScaler(quantile_range=(25, 75)).fit_transform(X)),\n",
    "    ('Data after quantile transformation (uniform pdf)',\n",
    "        QuantileTransformer(output_distribution='uniform')\n",
    "        .fit_transform(X)),\n",
    "    ('Data after quantile transformation (gaussian pdf)',\n",
    "        QuantileTransformer(output_distribution='normal')\n",
    "        .fit_transform(X)),\n",
    "    ('Data after sample-wise L2 normalizing',\n",
    "        Normalizer().fit_transform(X))\n",
    "]\n",
    "\n",
    "# scale the output between 0 and 1 for the colorbar\n",
    "y = minmax_scale(y_full)\n",
    "\n",
    "\n",
    "def create_axes(title, figsize=(16, 6)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    # define the axis for the first plot\n",
    "    left, width = 0.1, 0.22\n",
    "    bottom, height = 0.1, 0.7\n",
    "    bottom_h = height + 0.15\n",
    "    left_h = left + width + 0.02\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom_h, width, 0.1]\n",
    "    rect_histy = [left_h, bottom, 0.05, height]\n",
    "\n",
    "    ax_scatter = plt.axes(rect_scatter)\n",
    "    ax_histx = plt.axes(rect_histx)\n",
    "    ax_histy = plt.axes(rect_histy)\n",
    "\n",
    "    # define the axis for the zoomed-in plot\n",
    "    left = width + left + 0.2\n",
    "    left_h = left + width + 0.02\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom_h, width, 0.1]\n",
    "    rect_histy = [left_h, bottom, 0.05, height]\n",
    "\n",
    "    ax_scatter_zoom = plt.axes(rect_scatter)\n",
    "    ax_histx_zoom = plt.axes(rect_histx)\n",
    "    ax_histy_zoom = plt.axes(rect_histy)\n",
    "\n",
    "    # define the axis for the colorbar\n",
    "    left, width = width + left + 0.13, 0.01\n",
    "\n",
    "    rect_colorbar = [left, bottom, width, height]\n",
    "    ax_colorbar = plt.axes(rect_colorbar)\n",
    "\n",
    "    return ((ax_scatter, ax_histy, ax_histx),\n",
    "            (ax_scatter_zoom, ax_histy_zoom, ax_histx_zoom),\n",
    "            ax_colorbar)\n",
    "\n",
    "\n",
    "def plot_distribution(axes, X, y, hist_nbins=50, title=\"\",\n",
    "                      x0_label=\"\", x1_label=\"\"):\n",
    "    ax, hist_X1, hist_X0 = axes\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x0_label)\n",
    "    ax.set_ylabel(x1_label)\n",
    "\n",
    "    # The scatter plot\n",
    "    colors = cm.plasma_r(y)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.5, marker='o', s=5, lw=0, c=colors)\n",
    "\n",
    "    # Removing the top and the right spine for aesthetics\n",
    "    # make nice axis layout\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "\n",
    "    # Histogram for axis X1 (feature 5)\n",
    "    hist_X1.set_ylim(ax.get_ylim())\n",
    "    hist_X1.hist(X[:, 1], bins=hist_nbins, orientation='horizontal',\n",
    "                 color='grey', ec='grey')\n",
    "    hist_X1.axis('off')\n",
    "\n",
    "    # Histogram for axis X0 (feature 0)\n",
    "    hist_X0.set_xlim(ax.get_xlim())\n",
    "    hist_X0.hist(X[:, 0], bins=hist_nbins, orientation='vertical',\n",
    "                 color='grey', ec='grey')\n",
    "    hist_X0.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два графика будут построены для каждого преобразователя масштаба/нормализатора/преобразователя. \n",
    "Левая фигура показывает точечную диаграмму всех данных, в то время как правая\n",
    "исключает крайние значения, рассматривая лишь 99% датасета, исключая \n",
    "предельные выбросы. Кроме того, предельные распределения для каждого признака показаны \n",
    "сбоку от точечной диаграммы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(item_idx):\n",
    "    title, X = distributions[item_idx]\n",
    "    ax_zoom_out, ax_zoom_in, ax_colorbar = create_axes(title)\n",
    "    axarr = (ax_zoom_out, ax_zoom_in)\n",
    "    plot_distribution(axarr[0], X, y, hist_nbins=200,\n",
    "                      x0_label=\"Median Income\",\n",
    "                      x1_label=\"Number of households\",\n",
    "                      title=\"Full data\")\n",
    "\n",
    "    # zoom-in\n",
    "    zoom_in_percentile_range = (0, 99)\n",
    "    cutoffs_X0 = np.percentile(X[:, 0], zoom_in_percentile_range)\n",
    "    cutoffs_X1 = np.percentile(X[:, 1], zoom_in_percentile_range)\n",
    "\n",
    "    non_outliers_mask = (\n",
    "        np.all(X > [cutoffs_X0[0], cutoffs_X1[0]], axis=1) &\n",
    "        np.all(X < [cutoffs_X0[1], cutoffs_X1[1]], axis=1))\n",
    "    plot_distribution(axarr[1], X[non_outliers_mask], y[non_outliers_mask],\n",
    "                      hist_nbins=50,\n",
    "                      x0_label=\"Median Income\",\n",
    "                      x1_label=\"Number of households\",\n",
    "                      title=\"Zoom-in\")\n",
    "\n",
    "    norm = mpl.colors.Normalize(y_full.min(), y_full.max())\n",
    "    mpl.colorbar.ColorbarBase(ax_colorbar, cmap=cm.plasma_r,\n",
    "                              norm=norm, orientation='vertical',\n",
    "                              label='Color mapping for values of y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Исходные данные\n",
    "-------------\n",
    "\n",
    "Каждая отрисовка преобразования показывает 2 преобразованных признака, \n",
    "где левый график показывает полный датасет, а правый увеличен, чтобы \n",
    "показать датасет без предельных выбросов. Наибольшее количество образцов\n",
    "сгруппированы в определенном диапазоне, [0, 10] для медианы дохода и [0, 6]\n",
    "для количества проживающих семей. Заметьте, что есть и несколько предельных \n",
    "выбросов (некоторые блоки имеют более 1200 проживающих семей). Поэтому, \n",
    "была бы полезна некая специальная предварительная обработка, в зависимости \n",
    "от приложения. Ниже мы представим некоторые идеи и модели поведения этих \n",
    "методов предварительной обработки в присутствии предельных выбросов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler\n",
    "--------------\n",
    "\n",
    "``StandardScaler`` убирает среднее значение и масштабы для данных с единичной\n",
    "дисперсией. Однако, выбросы влияют на вычисление эмпирического среднего и \n",
    "стандартного отклонения, что сужает диапазон значений признаков, как \n",
    "указывает изображение ниже. Заметьте, что в конкретном случае это так, потому\n",
    "что выбросы для каждого признака имеют различные значимости, распределение \n",
    "преобразованных данных по каждому признаку очень различно: большинство данных \n",
    "лежат в промежутке [-2, 4] для преобразованной медианы дохода, в то время как \n",
    "те же данные втиснуты в меньший промежуток [-0.2, 0.2] для преобразованного \n",
    "количества проживающих семей.\n",
    "\n",
    "\n",
    "Поэтому ``StandardScaler`` не может гарантировать уравновешенность масштабов \n",
    "признаков при наличии выбросов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler\n",
    "------------\n",
    "\n",
    "``MinMaxScaler`` изменяет масштаб датасета так, что все значения признаков\n",
    "находятся в промежутке [0, 1], как показано ниже, в панели справа. Однако \n",
    "это масштабирование сжимает все не-выбросы в узкий промежуток [0, 0.005]\n",
    "для преобразованного количества проживающих семей.\n",
    "\n",
    "Как и ``StandardScaler``, ``MinMaxScaler`` очень чувствителен к наличию выбросов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxAbsScaler\n",
    "------------\n",
    "\n",
    "``MaxAbsScaler`` отличается от предыдущих преобразователей масштаба тем, \n",
    "что его абсолютные значения расположены в промежутке [0, 1]. При только\n",
    "положительных данных, данный преобразователь ведет себя так же, как и \n",
    "``MinMaxScaler``, поэтому он также страдает от наличия больших выбросов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RobustScaler\n",
    "------------\n",
    "\n",
    "В отличие от предыдущих преобразователей масштаба, центрирование и \n",
    "масштабирование этого преобразователя основано на перцентилях и поэтому\n",
    "не подвержено влиянию небольшого количества больших предельных выбросов.\n",
    "Следовательно, результирующий диапазон значений преобразованных признаков \n",
    "больше, чем в предыдущих преобразователях и, что более важно, значения \n",
    "приблизительно равны: для обоих признаков большая часть преобразованных \n",
    "значений лежит в промежутке [-2, 3], как показано на увеличенном рисунке.\n",
    "Заметьте, что выбросы сами по себе все еще существуют в преобразованных \n",
    "данных. Если отдельный выброс желаемо сохранить, то необходимо нелинейное\n",
    "преобразование (см. ниже).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantileTransformer (равномерный вывод)\n",
    "------------------------------------\n",
    "\n",
    "``QuantileTransformer`` производит нелинейное преобразование, такое, что \n",
    "плотность вероятности функции каждого признака будет соответствовать \n",
    "равномерному распределению. В этом случае, все данные будут входить\n",
    "в промежуток [0, 1], даже выбросы, которые больше нельзя разграничить с\n",
    "не-выбросами.\n",
    "\n",
    "Как и ``RobustScaler``, ``QuantileTransformer`` устойчив к выбросам:\n",
    "при добавлении или удалении выбросов из обучающей выборки, даст\n",
    "примерно такое же преобразование для данных. В отичие от ``RobustScaler``, \n",
    "``QuantileTransformer`` также автоматически коллапсирует любой выброс, \n",
    "устанавливая их в предварительно определенные рамки (0 и 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantileTransformer (вывод Гауссиана)\n",
    "-------------------------------------\n",
    "\n",
    "``QuantileTransformer`` имеет дополнительный параметр ``output_distribution``,\n",
    "позволяющий подбирать распределение Гаусса вместо равномерного распределения.\n",
    "Заметьте, что это беспараметрический преобразователь, который вводит насыщенность \n",
    "продуктами для крайних значений.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer\n",
    "----------\n",
    "\n",
    "``Normalizer`` изменяет масштаб вектора для каждого примера, чтобы получить\n",
    "единичную норму, независимо от распределения образцов.  Его видно на обоих\n",
    "рисунка ниже, где все образцы сгруппированы в единичный круг. В нашем \n",
    "примере есть два выбранных признака только с положительными значеними; \n",
    "поэтому, преобразованные данные лежат лишь в положительном квадранте. Этого\n",
    "бы не произошло, если бы некоторые искомые признаки имели смесь положительных\n",
    "и отрицательных значений.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
